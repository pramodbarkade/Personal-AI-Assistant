# ğŸ§  Personal AI Assistant (Local, Free, No API Keys)

A **fully local, ChatGPT-like AI assistant** built using **Ollama** and **open-source models**.
Runs on your own machine, **100% free**, with both **Python agent** and **Web UI** support.

No cloud.
No API keys.
No billing.

---

## âœ¨ Features

* âœ… Runs **entirely locally**
* âœ… **ChatGPT-like live streaming** responses
* âœ… **Web UI (HTML)** â€“ no backend required
* âœ… **Python AI agent** for automation & tools
* âœ… **Multiple models supported**
* âœ… **Model dropdown with install detection**
* âœ… **Single shared configuration (`models.json`)**
* âœ… Works offline (after model download)

---

## ğŸ— Architecture Overview

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      Ollama       â”‚
              â”‚  (Local AI Host)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Agent â”‚                 â”‚   Web UI     â”‚
â”‚ ai_agent.py  â”‚                 â”‚   ui.html    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Ollama** runs the AI models
* **Python agent** and **Web UI** are just clients
* Both talk to the same local AI engine

---

## ğŸ“ Project Structure

```
Personal-AI-Assistant/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ models.json        # Central model configuration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai_agent.py        # Python CLI AI agent
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ model_config.py
â”‚       â””â”€â”€ ollama_client.py
â”‚
â”œâ”€â”€ ui.html                # Web UI (ChatGPT-like)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Supported Models (Free)

| Model          | Category          | RAM    | Notes                   |
| -------------- | ----------------- | ------ | ----------------------- |
| **Phi-3 Mini** | Fast Chat         | ~4 GB  | Default, best balance   |
| **Mistral 7B** | High Quality Text | ~6 GB  | Better reasoning & code |
| **TinyLLaMA**  | Lightweight       | ~2 GB  | Low-resource fallback   |
| **Qwen 1.5B**  | Small but Smart   | ~3 GB  | Strong for size         |
| **LLaVA 7B**   | Vision (Optional) | ~10 GB | Image + text            |

> You can add/remove models easily via `config/models.json`.

---

## âš™ï¸ Prerequisites

* **OS:** Windows / macOS / Linux
* **RAM:** 8 GB minimum (16 GB recommended)
* **Python:** 3.10+
* **Internet:** Only for first model download

---

## ğŸš€ Step-by-Step Setup

### 1ï¸âƒ£ Install Ollama

Download and install Ollama:

ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

Verify:

```bash
ollama --version
```

---

### 2ï¸âƒ£ Download a Model (Recommended)

```bash
ollama pull phi3:mini
```

Optional (better quality):

```bash
ollama pull mistral
```

Verify:

```bash
ollama list
```

---

### 3ï¸âƒ£ Run the Python AI Agent

```bash
python src/ai_agent.py
```

Features:

* CLI chat
* Model switching
* Streaming output

---

### 4ï¸âƒ£ Run the Web UI

Start a lightweight local server:

```bash
python -m http.server 8000
```

Open in browser:

```
http://localhost:8000/ui.html
```

âœ” Model dropdown
âœ” Disabled models if not installed
âœ” Live typing responses

---

## âš™ï¸ Central Model Configuration

All models are defined in **one place**:

```
config/models.json
```

Both:

* Python agent
* Web UI

read from the same config.

This ensures:

* No duplication
* Consistent defaults
* Easy maintenance

---

## ğŸ”’ Privacy & Cost

* ğŸ” Data never leaves your machine
* ğŸ’° Cost = **â‚¹0 / $0**
* ğŸ”‘ No API keys
* ğŸ“¡ No cloud dependency

---

## ğŸ¥ Perfect for Demos & Learning

This project is ideal for:

* YouTube tutorials
* AI agent demos
* Local AI experimentation
* Learning system design
* Offline AI usage

---

## ğŸ›£ Roadmap (Optional)

* Conversation memory
* Tool usage (files, commands)
* Vision UI (image upload)
* Backend API (FastAPI)
* Deployment mode

---

## ğŸ“œ License

This project uses **open-source models**.
Please follow the individual model licenses when redistributing.

---

## ğŸ™Œ Author

Built for learning, demos, and community sharing.
Feel free to fork, extend, and improve.

---

### â­ If this helped you

Give the repo a star and share it with others building local AI ğŸš€